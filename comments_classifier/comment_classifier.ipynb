{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "source": [
    "! pip install YT-comments-scrapper==0.3"
   ],
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "Collecting YT-comments-scrapper==0.3\n",
      "  Downloading YT_comments_scrapper-0.3-py3-none-any.whl (3.9 kB)\n",
      "Installing collected packages: YT-comments-scrapper\n",
      "  Attempting uninstall: YT-comments-scrapper\n",
      "    Found existing installation: YT-comments-scrapper 0.2\n",
      "    Uninstalling YT-comments-scrapper-0.2:\n",
      "      Successfully uninstalled YT-comments-scrapper-0.2\n",
      "Successfully installed YT-comments-scrapper-0.3\n"
     ]
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "import pickle\n",
    "from yt_scrapper import YtScrapper\n",
    "import nltk\n",
    "from textblob import TextBlob\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "source": [
    "scrapper = YtScrapper(\"https://www.youtube.com/watch?v=kuhhT_cBtFU&t=2s\",100,\"/Users/lindaoranya/downloads/chromedriver\")"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "source": [
    "df = scrapper.scrape_comments()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "source": [
    "df.shape"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(924, 1)"
      ]
     },
     "metadata": {},
     "execution_count": 24
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "source": [
    "df_comments = df.copy()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "source": [
    "df"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                               comment\n",
       "0    LT\\nSKIP NAVIGATION\\nSIGN IN\\n0:02 / 2:48\\n#CN...\n",
       "1                                                     \n",
       "2    Bodycam video released by the Atlanta Police D...\n",
       "3    I always wonder why CNN never shows the whole ...\n",
       "4    Good parenting: “teaches about good and bad pe...\n",
       "..                                                 ...\n",
       "919  Facts:\\n1-The taser was not loaded cause the o...\n",
       "920      Plis not 'shorten' and 'combine' the video...\n",
       "921  Guy assaulted the police and it is his fault h...\n",
       "922  Why won't the Black Lives Matter movement call...\n",
       "923  Before you continue to YouTube\\nGoogle uses co...\n",
       "\n",
       "[924 rows x 1 columns]"
      ],
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>comment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>LT\\nSKIP NAVIGATION\\nSIGN IN\\n0:02 / 2:48\\n#CN...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Bodycam video released by the Atlanta Police D...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I always wonder why CNN never shows the whole ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Good parenting: “teaches about good and bad pe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>919</th>\n",
       "      <td>Facts:\\n1-The taser was not loaded cause the o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>920</th>\n",
       "      <td>Plis not 'shorten' and 'combine' the video...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>921</th>\n",
       "      <td>Guy assaulted the police and it is his fault h...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>922</th>\n",
       "      <td>Why won't the Black Lives Matter movement call...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>923</th>\n",
       "      <td>Before you continue to YouTube\\nGoogle uses co...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>924 rows × 1 columns</p>\n",
       "</div>"
      ]
     },
     "metadata": {},
     "execution_count": 81
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "source": [
    "df['polarity'] = df['comment'].apply(lambda x: TextBlob(x).sentiment.polarity)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "source": [
    "df['pol_class'] = np.where(df.polarity>0,1,-1)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "source": [
    "#get the stopwords for english\n",
    "stop_words = stopwords.words('english')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "source": [
    "#remove no and not from list of stopwords\n",
    "stop_words.remove('no')\n",
    "stop_words.remove('not')"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "source": [
    "stem_obj = PorterStemmer()\n",
    "lem_obj = WordNetLemmatizer()"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "source": [
    "corpus = []\n",
    "#Text Preprocessing without stemming    \n",
    "for i in range(0,len(df)):\n",
    "    review = re.sub('[^a-zA-Z]',' ',df.iloc[i,0])\n",
    "    review = review.lower().split()\n",
    "    \n",
    "    #Apply stemming and lemmatization of all words in review\n",
    "    review_updated = [lem_obj.lemmatize(lem_obj.lemmatize(word,pos='v'),pos='a')\\\n",
    "                     for word in review\\\n",
    "                     if word not in stop_words]\n",
    "    review_updated = ' '.join(review_updated)\n",
    "    corpus.append(review_updated)"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "source": [
    "countVector = CountVectorizer(max_features=2000)\n",
    "pickle.dump(countVector,open('transform.pkl','wb'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "source": [
    "X = countVector.fit_transform(corpus).toarray()\n",
    "\n",
    "words = countVector.get_feature_names()\n",
    "pickle.dump(words,open('vocabulary.pkl','wb'))"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "source": [
    "y = df.pol_class.values"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "source": [
    "X_train,X_test,y_train,y_test = train_test_split(X,y,test_size=0.3,random_state=42) \n"
   ],
   "outputs": [],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "source": [
    "#training\n",
    "rf_classifer = RandomForestClassifier(n_estimators=150,min_samples_split=5)\n",
    "rf_classifer.fit(X_train,y_train)\n",
    "rf_classifer.score(X_test,y_test)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "0.7482014388489209"
      ]
     },
     "metadata": {},
     "execution_count": 95
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "source": [
    "rf_classifer.predict(X_test)"
   ],
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "metadata": {},
     "execution_count": 98
    }
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "source": [
    "pickle.dump(rf_classifer,open('nlp_model.pkl','wb'))"
   ],
   "outputs": [],
   "metadata": {}
  }
 ],
 "metadata": {
  "orig_nbformat": 4,
  "language_info": {
   "name": "python",
   "version": "3.8.5",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kernelspec": {
   "name": "python3",
   "display_name": "Python 3.8.5 64-bit ('base': conda)"
  },
  "interpreter": {
   "hash": "96da96a43e8caf4c5de2287102d9bd8119e49b09090def16a113bb5d830b38b8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}